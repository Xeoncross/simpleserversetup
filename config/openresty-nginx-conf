# Default Nginx Config for Openresty-Nginx

user www-data www-data;
pid /run/nginx.pid;

# The maximum number of connections for Nginx is calculated by:
# max_clients = worker_processes * worker_connections
# auto = all cpu cores
worker_processes auto;

# Maximum open file descriptors per process; should be > worker_connections.
# Make sure to also set this at the OS level:
# https://cs.uwaterloo.ca/~brecht/servers/openfiles.html
worker_rlimit_nofile 8192;

events {
	# When you need > 8000 * cpu_cores connections, you start optimizing your OS,
	# and this is probably the point at which you hire people who are smarter than
	# you, as this is *a lot* of requests.
	worker_connections 8000;

	# Tells nginx to accept as many connections as possible after getting a
	# notification about a new connection
	# multi_accept on;

	# http://wiki.nginx.org/Optimizations
	# optmized to serve many clients with each thread
	# only available in Linux kernels which are later than 2.6
	# use epoll;
}

http {

	# Hide nginx version information.
	server_tokens off;
	types_hash_max_size 2048;

	# server_names_hash_bucket_size 64;
	# server_name_in_redirect off;

	include /etc/nginx/mime.types;
	default_type application/octet-stream;

	# With full unicode support
	charset UTF-8;

	##
	# Logging Settings
	##

	access_log /var/log/nginx/access.log;
	error_log /var/log/nginx/error.log;

	# How long to allow each connection to stay idle; longer values are better
	# for each individual client, particularly for SSL, but means that worker
	# connections are tied up longer. (Default: 65)
	keepalive_timeout 20;
	
	# send the client a "request timed out" if the body is not loaded by this time. Default 60.
	client_body_timeout 10;

	# If the client stops reading data, free up the stale client
	# connection after this much time. Default 60.
	send_timeout 4;

	# allow the server to close the connection after a client stops responding.
	# Frees up socket-associated memory.
	reset_timedout_connection on;

	# Size of the client request body, specified in the “Content-Length” request header field.
	client_max_body_size 50M;

	# Speed up file transfers by using sendfile() to copy directly
	# between descriptors rather than using read()/write().
	# Disable this for Vagrant boxes - sometimes causes problems
	sendfile on;
	
	# Tcp_nopush causes nginx to attempt to send its HTTP response head in one packet, 
	# instead of using partial frames. This is useful for prepending headers before calling sendfile, 
	# or for throughput optimization.
	tcp_nopush on;
	
	# Tell Nginx to enable the Nagle buffering algorithm for TCP packets, which
	# collates several smaller packets together into one larger packet, thus saving
	# bandwidth at the cost of a nearly imperceptible increase to latency. (removes TCP_NODELAY)
	# Set this to off to lower latency on multiple small packets.
	tcp_nodelay	off;

	# Enable Gzip compressed.
	gzip on;
	gzip_disable "msie6";
	
	# Enable compression both for HTTP/1.0 and HTTP/1.1 (required for CloudFront).
	gzip_http_version 1.0;
	
	# Compression level (1-9).
	# 5 is a perfect compromise between size and cpu usage, offering about
	# 75% reduction for most ascii files (almost identical to level 9).
	gzip_comp_level 5;
	
	# Don't compress anything that's already small and unlikely to shrink much
	# if at all (the default is 20 bytes, which is bad as that usually leads to
	# larger files after gzipping).
	gzip_min_length 256;
	
	# Compress data even for clients that are connecting to us via proxies,
	# identified by the "Via" header (required for CloudFront).
	gzip_proxied any;
	
	# Tell proxies to cache both the gzipped and regular version of a resource
	# whenever the client's Accept-Encoding capabilities header varies;
	# Avoids the issue where a non-gzip capable client (which is extremely rare
	# today) would display gibberish if their proxy gave them the gzipped version.
	gzip_vary on;
	
	# Compress all output labeled with one of the following MIME-types.
	gzip_types
	application/atom+xml
	application/javascript
	application/json
	application/rss+xml
	application/vnd.ms-fontobject
	application/x-font-ttf
	application/x-web-app-manifest+json
	application/xhtml+xml
	application/xml
	font/opentype
	image/svg+xml
	image/x-icon
	text/css
	text/plain
	text/x-component;
	# text/html is always compressed by HttpGzipModule
	
	# This should be turned on if you are going to have pre-compressed copies (.gz) of
	# static files available. If not it should be left off as it will cause extra I/O
	# for the check. It is best if you enable this in a location{} block for
	# a specific directory, or on an individual server{} level.
	# gzip_static on;

	# Protect against the BEAST attack by preferring RC4-SHA when using SSLv3 and TLS protocols.
	# Note that TLSv1.1 and TLSv1.2 are immune to the beast attack but only work with OpenSSL v1.0.1 and higher and has limited client support.
	# Ciphers set to best allow protection from Beast, while providing forwarding secrecy, as defined by Mozilla - https://wiki.mozilla.org/Security/Server_Side_TLS#Nginx
	ssl_protocols				SSLv3 TLSv1 TLSv1.1 TLSv1.2;
	ssl_ciphers					ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:ECDHE-RSA-RC4-SHA:ECDHE-ECDSA-RC4-SHA:AES128:AES256:RC4-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!3DES:!MD5:!PSK;
	ssl_prefer_server_ciphers	on;
	
	# Optimize SSL by caching session parameters for 10 minutes. This cuts down on the number of expensive SSL handshakes.
	# The handshake is the most CPU-intensive operation, and by default it is re-negotiated on every new/parallel connection.
	# By enabling a cache (of type "shared between all Nginx workers"), we tell the client to re-use the already negotiated state.
	# Further optimization can be achieved by raising keepalive_timeout, but that shouldn't be done unless you serve primarily HTTPS.
	ssl_session_cache	shared:SSL:10m; # a 1mb cache can hold about 4000 sessions, so we can hold 40000 sessions
	ssl_session_timeout	10m;
	
	# This default SSL certificate will be served whenever the client lacks support for SNI (Server Name Indication).
	# Make it a symlink to the most important certificate you have, so that users of IE 8 and below on WinXP can see your main site without SSL errors.
	#ssl_certificate			/etc/ssl/certs/ssl-cert-snakeoil.pem;
	#ssl_certificate_key		/etc/ssl/private/ssl-cert-snakeoil.key;
	
	# set search paths for pure Lua external libraries (';;' is the default path):
	# lua_package_path '/foo/bar/?.lua;/blah/?.lua;;';

	# set search paths for Lua external libraries written in C (can also use ';;'):
	# lua_package_cpath '/bar/baz/?.so;/blah/blah/?.so;;';

	##
	# nginx-naxsi config
	##

	include /etc/nginx/naxsi_core.rules;

	##
	# Virtual Host Configs
	##

	include /etc/nginx/conf.d/*.conf;
	include /etc/nginx/sites-enabled/*;

}

# As you make changes you can reload with
#     sudo service nginx reload
# If you want to stress-test it:
#     httperf --num-calls 100 --num-conns 10000 --max-connections 10000 --server localhost --port 80